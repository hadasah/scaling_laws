{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "lang = \"py\"\n",
    "run_lang = \"python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "\n",
    "# api = wandb.Api()\n",
    "# entity, project = \"loubnabnl\", \"scaling_laws\"  # set to your entity and project \n",
    "# runs = api.runs(entity + \"/\" + project) \n",
    "\n",
    "# summary_list, config_list, name_list = [], [], []\n",
    "# for run in runs: \n",
    "#     # .summary contains the output keys/values for metrics like accuracy.\n",
    "#     #  We call ._json_dict to omit large files \n",
    "#     summary_list.append(run.summary._json_dict)\n",
    "\n",
    "#     # .config contains the hyperparameters.\n",
    "#     #  We remove special values that start with _.\n",
    "#     config_list.append(\n",
    "#         {k: v for k,v in run.config.items()\n",
    "#          if not k.startswith('_')})\n",
    "\n",
    "#     # .name is the human-readable name of the run.\n",
    "#     name_list.append(run.name)\n",
    "\n",
    "# orig_runs_df = pd.DataFrame({\n",
    "#     \"summary\": summary_list,\n",
    "#     \"config\": config_list,\n",
    "#     \"name\": name_list\n",
    "#     })\n",
    "\n",
    "# def expand_dict_to_columns(df, col):\n",
    "#     return pd.concat([df.drop([col], axis=1),  pd.json_normalize(df[col])], axis=1)\n",
    "\n",
    "# run_df = expand_dict_to_columns(orig_runs_df, \"summary\")\n",
    "# run_df = expand_dict_to_columns(run_df, \"config\")\n",
    "\n",
    "# keep_cols = [c for c in run_df if \"lm-loss-validation/TEST_\" not in c]\n",
    "# run_df = run_df[keep_cols]\n",
    "\n",
    "# df_run = run_df[run_df[\"_step\"] >= .99 * run_df[\"train_iters\"]]\n",
    "# df_run.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_PROJECT_DIR = \"/fsx-onellm/margaretli/env_srcs/xlf/xlformers_n/scaling/data\"\n",
    "\n",
    "col_names = ['C', 'D', 'N', 'lr', 'Avg Train Loss', 'Max Train Loss', 'C4 Eval PPL', 'Wiki Eval PPL', 'C4 Eval Loss', 'Wiki Eval Loss']\n",
    "\n",
    "def read_data(csv_file, loss_name='C4 Eval Loss', col_names=col_names):\n",
    "    mins_only = []\n",
    "    df = pd.read_csv(csv_file, usecols=col_names,)\n",
    "    df.dropna(subset=[loss_name], inplace=True)\n",
    "\n",
    "    df = df.loc[(df['lr'] >= 0)]\n",
    "    n_vals = df['N'].unique()\n",
    "    d_vals = sorted(df['D'].unique())\n",
    "    for n in n_vals:\n",
    "        for d in d_vals:\n",
    "            cd_df = df[(df['N'] == n) & (df['D'] == d)]\n",
    "            if cd_df.empty:\n",
    "                continue\n",
    "            min_index = cd_df[loss_name].idxmin()\n",
    "            # print(min_index)\n",
    "            # print(cd_df)\n",
    "            # print(cd_df.loc[min_index])\n",
    "            mins_only.append(cd_df.loc[min_index])\n",
    "\n",
    "    mins_only_df = pd.DataFrame(mins_only)\n",
    "    # print(mins_only_df.N.values[:5].astype(np.longdouble))\n",
    "    # print(mins_only_df['N'].values[:5].astype(np.longdouble))\n",
    "    # print(np.fromstring(mins_only_df.N.values[:5], dtype=np.longdouble))\n",
    "\n",
    "    print(mins_only_df)\n",
    "    # df.rename(columns={})\n",
    "    return mins_only_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def loss(inp, params):\n",
    "    a, b, e, alpha, beta = params[0], params[1], params[2], params[3], params[4]\n",
    "    pre_lse = torch.stack([a - alpha*torch.log(inp[:, 0]), b - beta*torch.log(inp[:, 1]), e.expand((inp.shape[0]))])\n",
    "    post_lse = torch.logsumexp(pre_lse, dim=0)\n",
    "    # huber_loss = torch.nn.functional.huber_loss(post_lse, torch.log(inp[:, 2]), delta=1e-3, reduction='none')\n",
    "    huber_loss = torch.nn.functional.huber_loss(post_lse, torch.log(inp[:, 2]), delta=10, reduction='none')\n",
    "    return huber_loss.sum()\n",
    "\n",
    "def minimize_loss(inp, init_params=[6, 6, -1, 0.28, 0.32], steps=50):\n",
    "    params = torch.nn.Parameter(data=torch.Tensor(init_params))\n",
    "    \n",
    "    lbfgs = torch.optim.LBFGS([params],\n",
    "                    lr=1e-1,\n",
    "                    history_size=10, \n",
    "                    max_iter=20, \n",
    "                    line_search_fn=\"strong_wolfe\")\n",
    "\n",
    "    def closure():\n",
    "        lbfgs.zero_grad()\n",
    "        l = loss(inp, params)\n",
    "        l.backward()\n",
    "        return l\n",
    "\n",
    "    history_lbfgs = []\n",
    "    for i in range(steps):\n",
    "        l = lbfgs.step(closure)\n",
    "    return l, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        lr  Avg Train Loss  Max Train Loss  C4 Eval PPL  Wiki Eval PPL  \\\n",
      "4    0.004           4.957           5.185      146.194        216.300   \n",
      "12   0.004           4.717           5.044      119.259        166.031   \n",
      "17   0.004           4.453           4.659       89.148        115.380   \n",
      "21   0.004           3.999           4.218       61.665         70.939   \n",
      "25   0.004           3.736           4.058       46.984         47.592   \n",
      "29   0.004           3.533           3.764       39.858         35.852   \n",
      "33   0.002           4.925           5.171      141.632        224.183   \n",
      "37   0.002           4.683           5.024      114.945        168.517   \n",
      "42   0.004           3.880           4.109       55.653         62.826   \n",
      "46   0.004           3.603           3.968       41.767         39.030   \n",
      "50   0.004           3.448           3.680       36.775         32.393   \n",
      "54   0.004           3.384           3.679       34.108         29.042   \n",
      "58   0.004           3.312           3.599       32.342         26.802   \n",
      "62   0.002           4.643           4.973      110.797        162.453   \n",
      "66   0.002           4.321           4.538       79.123        102.901   \n",
      "74   0.002           3.835           4.065       53.307         59.325   \n",
      "79   0.002           3.549           3.924       39.643         36.808   \n",
      "84   0.004           3.390           3.625       34.712         30.659   \n",
      "88   0.004           3.250           3.529       30.378         25.104   \n",
      "92   0.004           3.201           3.438       28.080         22.326   \n",
      "96   0.002           4.971           5.216      147.519        236.586   \n",
      "101  0.004           4.734           5.059      120.748        175.021   \n",
      "105  0.004           4.341           4.559       80.451        106.232   \n",
      "109  0.004           3.820           4.048       52.464         60.188   \n",
      "113  0.004           3.521           3.902       38.631         35.934   \n",
      "117  0.004           3.348           3.581       33.370         29.302   \n",
      "121  0.004           3.295           3.593       31.304         26.355   \n",
      "125  0.004           3.215           3.495       29.460         24.049   \n",
      "129  0.002           3.850           4.069       53.599         63.878   \n",
      "133  0.002           3.512           3.893       37.959         36.726   \n",
      "141  0.002           3.320           3.551       32.382         29.010   \n",
      "146  0.002           3.245           3.546       29.709         25.333   \n",
      "150  0.002           3.163           3.441       27.800         22.986   \n",
      "154  0.002           3.114           3.467       26.355         21.154   \n",
      "158  0.002           3.106           3.342       25.531         20.245   \n",
      "162  0.002           3.013           3.292       24.104         18.628   \n",
      "167  0.002           3.765           3.988       49.540         58.191   \n",
      "171  0.002           3.445           3.838       35.667         34.073   \n",
      "175  0.002           3.260           3.492       30.456         27.134   \n",
      "179  0.002           3.174           3.488       27.671         23.507   \n",
      "183  0.002           3.092           3.371       25.875         21.285   \n",
      "187  0.002           3.037           3.276       23.837         18.773   \n",
      "191  0.002           2.944           3.227       22.524         17.297   \n",
      "195  0.002           2.908           3.304       21.594         16.315   \n",
      "199  0.002           3.654           3.889       45.125         42.395   \n",
      "203  0.002           3.050           3.327       24.771         20.313   \n",
      "211  0.002           2.993           3.229       22.757         17.906   \n",
      "216  0.002           2.899           3.182       21.522         16.467   \n",
      "220  0.002           2.864           3.263       20.629         15.535   \n",
      "224  0.002           2.815           3.157       19.575         14.377   \n",
      "234  0.001           2.725           3.060       17.837         12.987   \n",
      "244  0.001           2.490           2.921       14.456          9.629   \n",
      "\n",
      "     C4 Eval Loss  Wiki Eval Loss             C             D            N  \n",
      "4           4.985           5.377  4.470000e+16  2.097152e+08   12047168.0  \n",
      "12          4.781           5.112  5.590000e+16  2.621440e+08   12047168.0  \n",
      "17          4.490           4.748  8.050000e+16  3.774874e+08   12047168.0  \n",
      "21          4.122           4.262  1.120000e+17  5.242880e+08   12047168.0  \n",
      "25          3.850           3.863  1.680000e+17  7.864320e+08   12047168.0  \n",
      "29          3.685           3.579  2.240000e+17  1.048576e+09   12047168.0  \n",
      "33          4.953           5.412  5.540000e+16  2.097152e+08   16865856.0  \n",
      "37          4.744           5.127  6.930000e+16  2.621440e+08   16865856.0  \n",
      "42          4.019           4.140  1.390000e+17  5.242880e+08   16865856.0  \n",
      "46          3.732           3.664  2.080000e+17  7.864320e+08   16865856.0  \n",
      "50          3.605           3.478  2.770000e+17  1.048576e+09   16865856.0  \n",
      "54          3.530           3.369  3.460000e+17  1.310720e+09   16865856.0  \n",
      "58          3.476           3.288  4.160000e+17  1.572864e+09   16865856.0  \n",
      "62          4.708           5.090  9.170000e+16  2.621440e+08   25174528.0  \n",
      "66          4.371           4.634  1.320000e+17  3.774874e+08   25174528.0  \n",
      "74          3.976           4.083  1.830000e+17  5.242880e+08   25174528.0  \n",
      "79          3.680           3.606  2.750000e+17  7.864320e+08   25174528.0  \n",
      "84          3.547           3.423  3.670000e+17  1.048576e+09   25174528.0  \n",
      "88          3.414           3.223  5.500000e+17  1.572864e+09   25174528.0  \n",
      "92          3.335           3.106  7.340000e+17  2.097152e+09   25174528.0  \n",
      "96          4.994           5.466  9.500000e+16  2.097152e+08   35842752.0  \n",
      "101         4.794           5.165  1.190000e+17  2.621440e+08   35842752.0  \n",
      "105         4.388           4.666  1.710000e+17  3.774874e+08   35842752.0  \n",
      "109         3.960           4.097  2.370000e+17  5.242880e+08   35842752.0  \n",
      "113         3.654           3.582  3.560000e+17  7.864320e+08   35842752.0  \n",
      "117         3.508           3.378  4.750000e+17  1.048576e+09   35842752.0  \n",
      "121         3.444           3.272  5.940000e+17  1.310720e+09   35842752.0  \n",
      "125         3.383           3.180  7.120000e+17  1.572864e+09   35842752.0  \n",
      "129         3.982           4.157  3.020000e+17  5.242880e+08   49165440.0  \n",
      "133         3.636           3.603  4.520000e+17  7.864320e+08   49165440.0  \n",
      "141         3.478           3.368  6.030000e+17  1.048576e+09   49165440.0  \n",
      "146         3.391           3.232  7.540000e+17  1.310720e+09   49165440.0  \n",
      "150         3.325           3.135  9.050000e+17  1.572864e+09   49165440.0  \n",
      "154         3.272           3.052  1.090000e+18  1.887437e+09   49165440.0  \n",
      "158         3.240           3.008  1.210000e+18  2.097152e+09   49165440.0  \n",
      "162         3.182           2.925  1.510000e+18  2.621440e+09   49165440.0  \n",
      "167         3.903           4.064  4.040000e+17  5.242880e+08   71386304.0  \n",
      "171         3.574           3.528  6.060000e+17  7.864320e+08   71386304.0  \n",
      "175         3.416           3.301  8.080000e+17  1.048576e+09   71386304.0  \n",
      "179         3.320           3.157  1.010000e+18  1.310720e+09   71386304.0  \n",
      "183         3.253           3.058  1.210000e+18  1.572864e+09   71386304.0  \n",
      "187         3.171           2.932  1.620000e+18  2.097152e+09   71386304.0  \n",
      "191         3.115           2.851  2.020000e+18  2.621440e+09   71386304.0  \n",
      "195         3.072           2.792  2.430000e+18  3.145728e+09   71386304.0  \n",
      "199         3.809           3.747  1.060000e+18  1.048576e+09   99112704.0  \n",
      "203         3.210           3.011  1.580000e+18  1.572864e+09   99112704.0  \n",
      "211         3.125           2.885  2.110000e+18  2.097152e+09   99112704.0  \n",
      "216         3.069           2.801  2.640000e+18  2.621440e+09   99112704.0  \n",
      "220         3.027           2.743  3.170000e+18  3.145728e+09   99112704.0  \n",
      "224         2.974           2.666  4.220000e+18  4.194304e+09   99112704.0  \n",
      "234         2.881           2.564  7.560000e+18  4.194304e+09  199101120.0  \n",
      "244         2.671           2.265  1.510000e+19  8.388608e+09  393268480.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [04:05<00:00, 49.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0083, grad_fn=<SumBackward0>)\n",
      "[ 1.6370947e+00  1.2307936e+01 -4.4104099e+01  3.7521522e-02\n",
      "  5.9921348e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_name = \"C4 Eval Loss\"\n",
    "csv_file = \"/fsx-onellm/margaretli/env_srcs/xlf/xlformers_n/scaling/data/data.csv\"\n",
    "project_dir=DEFAULT_PROJECT_DIR\n",
    "\n",
    "fit_df = read_data(csv_file=csv_file, loss_name=loss_name)\n",
    "# fit_df = fit_df[fit_df['N'] < 50000000]\n",
    "\n",
    "inp = torch.Tensor([[N, D, L] for N, D, L in \n",
    "                    zip(fit_df[\"N\"], fit_df[\"D\"], fit_df[loss_name])])\n",
    "inp.require_grad = True\n",
    "\n",
    "min_loss = 1e10\n",
    "for a in tqdm(np.linspace(0, 10, 5)):\n",
    "    for b in np.linspace(0, 10, 5):\n",
    "        for e in np.linspace(-1, 2, 4):\n",
    "            for alpha in np.linspace(0, 1, 4):\n",
    "                for beta in np.linspace(0, 1, 4):\n",
    "                    l, params = minimize_loss(inp, [a, b, e, alpha, beta])\n",
    "                    if l < min_loss:\n",
    "                        min_loss = l\n",
    "                        best_params = params.detach().numpy()\n",
    "\n",
    "print(min_loss)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 0.941072\n",
      "b 0.058928\n",
      "G 6.791991589901064e-10\n"
     ]
    }
   ],
   "source": [
    "opt_alpha = best_params[-2]\n",
    "opt_beta = best_params[-1]\n",
    "\n",
    "opt_a =  opt_beta / (opt_alpha+opt_beta)\n",
    "opt_b =  opt_alpha / (opt_alpha+opt_beta)\n",
    "\n",
    "A = np.exp(best_params[0])\n",
    "B = np.exp(best_params[1])\n",
    "G = ((opt_alpha*A)/(opt_beta*B))**(1/(opt_alpha+opt_beta))\n",
    "\n",
    "print(\"a\", opt_a)\n",
    "print(\"b\", opt_b)\n",
    "print(\"G\", G)\n",
    "\n",
    "def opt_N_D(C):\n",
    "    opt_N = G*(C/6)**opt_a\n",
    "    opt_D = (1/G)*(C/6)**opt_b\n",
    "    return opt_N, opt_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compute</th>\n",
       "      <th>parameters (B)</th>\n",
       "      <th>tokens (B)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.920000e+19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>18.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.210000e+20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>20.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.230000e+22</td>\n",
       "      <td>77.25</td>\n",
       "      <td>26.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.760000e+23</td>\n",
       "      <td>2883.82</td>\n",
       "      <td>33.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.850000e+24</td>\n",
       "      <td>17234.12</td>\n",
       "      <td>37.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.900000e+24</td>\n",
       "      <td>41917.26</td>\n",
       "      <td>39.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.430000e+25</td>\n",
       "      <td>134974.20</td>\n",
       "      <td>42.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.270000e+26</td>\n",
       "      <td>462657.10</td>\n",
       "      <td>45.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.300000e+28</td>\n",
       "      <td>36053325.81</td>\n",
       "      <td>60.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        compute parameters (B) tokens (B)\n",
       "0  1.920000e+19           0.18      18.13\n",
       "1  1.210000e+20           1.00      20.21\n",
       "2  1.230000e+22          77.25      26.54\n",
       "3  5.760000e+23        2883.82      33.29\n",
       "4  3.850000e+24       17234.12      37.23\n",
       "5  9.900000e+24       41917.26      39.36\n",
       "6  3.430000e+25      134974.20      42.35\n",
       "7  1.270000e+26      462657.10      45.75\n",
       "8  1.300000e+28    36053325.81      60.10"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaling = []\n",
    "\n",
    "for C in [1.92e19, 1.21e20, 1.23e22, 5.76e23, 3.85e24, 9.90e24, 3.43e25, 1.27e26, 1.30e28]:\n",
    "    N, D = opt_N_D(C)\n",
    "    scaling.append(\n",
    "        {\"compute\": f\"{C:e}\",\n",
    "         \"parameters (B)\": f\"{N/1e9:.2f}\",\n",
    "         \"tokens (B)\": f\"{D/1e9:.2f}\",\n",
    "        }\n",
    "    )\n",
    "     \n",
    "pd.DataFrame(scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2020082572609923"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scaling_law(N, D, params):\n",
    "    a, b, e, alpha, beta = params\n",
    "    A = np.exp(a)\n",
    "    B = np.exp(b)\n",
    "    E = np.exp(e)\n",
    "    \n",
    "    L = E + (A / (N**alpha)) + (B /(D**beta))\n",
    "    \n",
    "    return L\n",
    "scaling_law(1e10, 100e9, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'N'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3696810/819571701.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# color_map={\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#            \"3e+18\": \"orange\",\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#            \"6e+18\": \"black\",\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;31m#            \"3e+18\": \"brown\",\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;31m#            \"1e+19\": \"green\",\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#            \"3e+19\": \"purple\",\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m#            \"6e+19\": \"red\",\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fsx-onellm/margaretli/miniforge3/envs/mlexp/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_format_argument_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallow_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/fsx-onellm/margaretli/miniforge3/envs/mlexp/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   6908\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6909\u001b[0m             \u001b[0;31m# len(by) == 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6911\u001b[0m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6912\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6914\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6915\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fsx-onellm/margaretli/miniforge3/envs/mlexp/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1848\u001b[0m             )\n\u001b[1;32m   1849\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1850\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'N'"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "color_map={\n",
    "           \"3e+18\": \"orange\",\n",
    "           \"6e+18\": \"black\",\n",
    "           \"3e+18\": \"brown\",\n",
    "           \"1e+19\": \"green\",\n",
    "           \"3e+19\": \"purple\",\n",
    "           \"6e+19\": \"red\",\n",
    "           \"1e+20\": \"blue\",\n",
    "           \"3e+20\": \"pink\",\n",
    "           \"6e+20\": \"gold\",\n",
    "           \"1e+21\": \"silver\",\n",
    "          }\n",
    "fit_df.head(4)\n",
    "\n",
    "# fit_df['C'] = fit_df['C'].astype(str)\n",
    "fig = px.scatter(fit_df, x='N', y=loss_name, color='C', \n",
    "                 log_x=True, color_discrete_map=color_map)\n",
    "\n",
    "for compute in color_map.keys():\n",
    "    tmp_df = fit_df[fit_df['C'] == compute]\n",
    "    df_d = list() \n",
    "    for _, row in tmp_df.iterrows():\n",
    "        pred = scaling_law(row['N'], row['D'], best_params)\n",
    "        df_d.append({'prediction': pred, 'N': row['N'], 'D': row['D']})\n",
    "    fig2 = px.line(pd.DataFrame(df_d).sort_values('N'), \n",
    "                   x='N', y='prediction', log_x=True)\n",
    "    fig2.update_traces(line_color=color_map[compute], line_width=2)\n",
    "    fig = go.Figure(data=fig.data + fig2.data)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlexp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
