{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize as opt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, HuberRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x, a, b, c):\n",
    "  # print(type(x[0]), type(a), type(b), type(c))\n",
    "  return a * np.power(x, -b) + c\n",
    "\n",
    "def func_rev(x, a, b, c):\n",
    "  # print(type(x[0]), type(a), type(b), type(c))\n",
    "  return a * np.power(x, b) + c\n",
    "\n",
    "\n",
    "def get_best_fit(x, y, p0=[25.85993457, 0.15299458, 1.61171928], f=func_rev):\n",
    "  xs, ys = zip(*sorted(zip(x, y)))\n",
    "  xs = list(xs)\n",
    "  ys = list(ys)\n",
    "  optimizedParameters, pcov = opt.curve_fit(f, xs, ys, p0=p0);\n",
    "  print(optimizedParameters)\n",
    "  YS = [f(a, *optimizedParameters) for a in xs]\n",
    "  # Use the optimized parameters to plot the best fit\n",
    "  return xs, YS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func2(X, a, b, c):\n",
    "  # print(type(x[0]), type(a), type(b), type(c))\n",
    "  N, D = X[0], X[1]\n",
    "  return a * np.power(N * D, -b) + c # * np.power(D, -d) + e\n",
    "\n",
    "def get_scaling_fit(x1, x2, y):\n",
    "  x1s, x2s, ys = zip(*sorted(zip(x1, x2, y)))\n",
    "  x1s = list(x1s)\n",
    "  x2s = list(x2s)\n",
    "  ys = list(ys)\n",
    "  # optimizedParameters, pcov = opt.fmin_l_bfgs_b(func2, [x1s, x2s], ys) #p0=[10., -0.07,  1., -1., .1]) #[1, .1, 1, .1, 1]); # p0=[10, 0.1, 1, 1, 1]\n",
    "  optimizedParameters, pcov = opt.curve_fit(func2, [x1s, x2s], ys, p0=[1., .2, 1.]) # ,p0=[14.0572608,   0.0967392,   1.,          1. ,         0.79611877]) # [10., .1,  1., 1., .1]) #[1, .1, 1, .1, 1]); # p0=[10, 0.1, 1, 1, 1]\n",
    "  print(optimizedParameters)\n",
    "  YS = [func2([x, y], *optimizedParameters) for x, y in zip(x1s, x2s)]\n",
    "  # Use the optimized parameters to plot the best fit\n",
    "  return x1s, x2s, YS, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func23(X, a):\n",
    "  # print(type(x[0]), type(a), type(b), type(c))\n",
    "  p = [2.09176863e+02, 1.18897717e-01, 1.86816507e+00]\n",
    "  N, D = X[0], X[1]\n",
    "  return (p[0] * np.power( N * D * a, -p[1]) + p[2])  # * np.power(D, -d) + e\n",
    "\n",
    "def get_scaling_fit2(x1, x2, y):\n",
    "  x1s, x2s, ys = zip(*sorted(zip(x1, x2, y)))\n",
    "  x1s = list(x1s)\n",
    "  x2s = list(x2s)\n",
    "  ys = list(ys)\n",
    "  # optimizedParameters, pcov = opt.fmin_l_bfgs_b(func2, [x1s, x2s], ys) #p0=[10., -0.07,  1., -1., .1]) #[1, .1, 1, .1, 1]); # p0=[10, 0.1, 1, 1, 1]\n",
    "  optimizedParameters, pcov = opt.curve_fit(func23, [x1s, x2s], ys) # ,p0=[14.0572608,   0.0967392,   1.,          1. ,         0.79611877]) # [10., .1,  1., 1., .1]) #[1, .1, 1, .1, 1]); # p0=[10, 0.1, 1, 1, 1]\n",
    "  print(optimizedParameters)\n",
    "  YS = [func23([x, y], *optimizedParameters) for x, y in zip(x1s, x2s)]\n",
    "  # Use the optimized parameters to plot the best fit\n",
    "  return x1s, x2s, YS, ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        lr  Avg Train Loss  Max Train Loss  C4 Eval PPL  Wiki Eval PPL  \\\n",
      "4    0.004           4.957           5.185      146.194        216.300   \n",
      "12   0.004           4.717           5.044      119.259        166.031   \n",
      "17   0.004           4.453           4.659       89.148        115.380   \n",
      "21   0.004           3.999           4.218       61.665         70.939   \n",
      "25   0.004           3.736           4.058       46.984         47.592   \n",
      "29   0.004           3.533           3.764       39.858         35.852   \n",
      "33   0.002           4.925           5.171      141.632        224.183   \n",
      "37   0.002           4.683           5.024      114.945        168.517   \n",
      "42   0.004           3.880           4.109       55.653         62.826   \n",
      "46   0.004           3.603           3.968       41.767         39.030   \n",
      "50   0.004           3.448           3.680       36.775         32.393   \n",
      "54   0.004           3.384           3.679       34.108         29.042   \n",
      "58   0.004           3.312           3.599       32.342         26.802   \n",
      "62   0.002           4.643           4.973      110.797        162.453   \n",
      "66   0.002           4.321           4.538       79.123        102.901   \n",
      "74   0.002           3.835           4.065       53.307         59.325   \n",
      "79   0.002           3.549           3.924       39.643         36.808   \n",
      "84   0.004           3.390           3.625       34.712         30.659   \n",
      "88   0.004           3.250           3.529       30.378         25.104   \n",
      "92   0.004           3.201           3.438       28.080         22.326   \n",
      "96   0.002           4.971           5.216      147.519        236.586   \n",
      "101  0.004           4.734           5.059      120.748        175.021   \n",
      "105  0.004           4.341           4.559       80.451        106.232   \n",
      "109  0.004           3.820           4.048       52.464         60.188   \n",
      "113  0.004           3.521           3.902       38.631         35.934   \n",
      "117  0.004           3.348           3.581       33.370         29.302   \n",
      "121  0.004           3.295           3.593       31.304         26.355   \n",
      "125  0.004           3.215           3.495       29.460         24.049   \n",
      "129  0.002           3.850           4.069       53.599         63.878   \n",
      "133  0.002           3.512           3.893       37.959         36.726   \n",
      "141  0.002           3.320           3.551       32.382         29.010   \n",
      "146  0.002           3.245           3.546       29.709         25.333   \n",
      "150  0.002           3.163           3.441       27.800         22.986   \n",
      "154  0.002           3.114           3.467       26.355         21.154   \n",
      "158  0.002           3.106           3.342       25.531         20.245   \n",
      "162  0.002           3.013           3.292       24.104         18.628   \n",
      "\n",
      "     C4 Eval Loss  Wiki Eval Loss             C             D           N  \n",
      "4           4.985           5.377  1.515884e+16  2.097152e+08  12047168.0  \n",
      "12          4.781           5.112  1.894856e+16  2.621440e+08  12047168.0  \n",
      "17          4.490           4.748  2.728592e+16  3.774874e+08  12047168.0  \n",
      "21          4.122           4.262  3.789711e+16  5.242880e+08  12047168.0  \n",
      "25          3.850           3.863  5.684567e+16  7.864320e+08  12047168.0  \n",
      "29          3.685           3.579  7.579423e+16  1.048576e+09  12047168.0  \n",
      "33          4.953           5.412  2.122216e+16  2.097152e+08  16865856.0  \n",
      "37          4.744           5.127  2.652770e+16  2.621440e+08  16865856.0  \n",
      "42          4.019           4.140  5.305540e+16  5.242880e+08  16865856.0  \n",
      "46          3.732           3.664  7.958309e+16  7.864320e+08  16865856.0  \n",
      "50          3.605           3.478  1.061108e+17  1.048576e+09  16865856.0  \n",
      "54          3.530           3.369  1.326385e+17  1.310720e+09  16865856.0  \n",
      "58          3.476           3.288  1.591662e+17  1.572864e+09  16865856.0  \n",
      "62          4.708           5.090  3.959611e+16  2.621440e+08  25174528.0  \n",
      "66          4.371           4.634  5.701840e+16  3.774874e+08  25174528.0  \n",
      "74          3.976           4.083  7.919222e+16  5.242880e+08  25174528.0  \n",
      "79          3.680           3.606  1.187883e+17  7.864320e+08  25174528.0  \n",
      "84          3.547           3.423  1.583844e+17  1.048576e+09  25174528.0  \n",
      "88          3.414           3.223  2.375766e+17  1.572864e+09  25174528.0  \n",
      "92          3.335           3.106  3.167689e+17  2.097152e+09  25174528.0  \n",
      "96          4.994           5.466  4.510062e+16  2.097152e+08  35842752.0  \n",
      "101         4.794           5.165  5.637577e+16  2.621440e+08  35842752.0  \n",
      "105         4.388           4.666  8.118112e+16  3.774874e+08  35842752.0  \n",
      "109         3.960           4.097  1.127516e+17  5.242880e+08  35842752.0  \n",
      "113         3.654           3.582  1.691273e+17  7.864320e+08  35842752.0  \n",
      "117         3.508           3.378  2.255031e+17  1.048576e+09  35842752.0  \n",
      "121         3.444           3.272  2.818789e+17  1.310720e+09  35842752.0  \n",
      "125         3.383           3.180  3.382546e+17  1.572864e+09  35842752.0  \n",
      "129         3.982           4.157  1.546611e+17  5.242880e+08  49165440.0  \n",
      "133         3.636           3.603  2.319916e+17  7.864320e+08  49165440.0  \n",
      "141         3.478           3.368  3.093222e+17  1.048576e+09  49165440.0  \n",
      "146         3.391           3.232  3.866528e+17  1.310720e+09  49165440.0  \n",
      "150         3.325           3.135  4.639833e+17  1.572864e+09  49165440.0  \n",
      "154         3.272           3.052  5.567800e+17  1.887437e+09  49165440.0  \n",
      "158         3.240           3.008  6.186444e+17  2.097152e+09  49165440.0  \n",
      "162         3.182           2.925  7.733055e+17  2.621440e+09  49165440.0  \n",
      "[4.10448238]\n",
      "12047168.0, 209715200.0, 4.475967992757602, 4.985\n",
      "12047168.0, 262144000.0, 4.407689461273421, 4.781\n",
      "12047168.0, 377487360.0, 4.299940407689122, 4.49\n",
      "12047168.0, 524288000.0, 4.206790184195714, 4.122\n",
      "12047168.0, 786432000.0, 4.0967221416620605, 3.85\n",
      "12047168.0, 1048576000.0, 4.021783851351594, 3.685\n",
      "16865856.0, 209715200.0, 4.373703258820217, 4.953\n",
      "16865856.0, 262144000.0, 4.308102263201545, 4.744\n",
      "16865856.0, 524288000.0, 4.115081231423463, 4.019\n",
      "16865856.0, 786432000.0, 4.009329496301879, 3.732\n",
      "16865856.0, 1048576000.0, 3.93732990364124, 3.605\n",
      "16865856.0, 1310720000.0, 3.883154208458592, 3.53\n",
      "16865856.0, 1572864000.0, 3.8399440842827195, 3.476\n",
      "25174528.0, 262144000.0, 4.194627474660303, 4.708\n",
      "25174528.0, 377487360.0, 4.095918392297088, 4.371\n",
      "25174528.0, 524288000.0, 4.010583321806014, 3.976\n",
      "25174528.0, 786432000.0, 3.909749809913383, 3.68\n",
      "25174528.0, 1048576000.0, 3.8410987208843075, 3.547\n",
      "25174528.0, 1572864000.0, 3.7482420489519646, 3.414\n",
      "25174528.0, 2097152000.0, 3.685021880060507, 3.335\n",
      "35842752.0, 209715200.0, 4.158899540872855, 4.994\n",
      "35842752.0, 262144000.0, 4.098922621479729, 4.794\n",
      "35842752.0, 377487360.0, 4.004274184247181, 4.388\n",
      "35842752.0, 524288000.0, 3.922449585438839, 3.96\n",
      "35842752.0, 786432000.0, 3.825764112402127, 3.654\n",
      "35842752.0, 1048576000.0, 3.759937157725299, 3.508\n",
      "35842752.0, 1310720000.0, 3.710406029845413, 3.444\n",
      "35842752.0, 1572864000.0, 3.670900377374406, 3.383\n",
      "49165440.0, 524288000.0, 3.846686963929872, 3.982\n",
      "49165440.0, 786432000.0, 3.7535672797817217, 3.636\n",
      "49165440.0, 1048576000.0, 3.6901680426945402, 3.478\n",
      "49165440.0, 1310720000.0, 3.6424636374844077, 3.391\n",
      "49165440.0, 1572864000.0, 3.6044149651800383, 3.325\n",
      "49165440.0, 1887436800.0, 3.5671822217676024, 3.272\n",
      "49165440.0, 2097152000.0, 3.5460311793883283, 3.24\n",
      "49165440.0, 2621440000.0, 3.502100622759084, 3.182\n"
     ]
    }
   ],
   "source": [
    "DEFAULT_PROJECT_DIR = \"/fsx-onellm/margaretli/env_srcs/xlf/xlformers_n/scaling/data\"\n",
    "\n",
    "col_names = ['C', 'D', 'N', 'lr', 'Avg Train Loss', 'Max Train Loss', 'C4 Eval PPL', 'Wiki Eval PPL', 'C4 Eval Loss', 'Wiki Eval Loss']\n",
    "\n",
    "loss_name = \"C4 Eval Loss\"\n",
    "csv_file = \"/fsx-onellm/margaretli/env_srcs/xlf/xlformers_n/scaling/data/data.csv\"\n",
    "project_dir=DEFAULT_PROJECT_DIR\n",
    "\n",
    "def read_data(csv_file, loss_name='C4 Eval Loss', col_names=col_names):\n",
    "    mins_only = []\n",
    "    df = pd.read_csv(csv_file, usecols=col_names,)\n",
    "    df = df.loc[(df['lr'] >= 0)]\n",
    "    n_vals = df['N'].unique()\n",
    "    d_vals = sorted(df['D'].unique())\n",
    "    for n in n_vals:\n",
    "        for d in d_vals:\n",
    "            cd_df = df[(df['N'] == n) & (df['D'] == d)]\n",
    "            if cd_df.empty:\n",
    "                continue\n",
    "            min_index = cd_df['C4 Eval Loss'].idxmin()\n",
    "            # print(min_index)\n",
    "            # print(cd_df)\n",
    "            # print(cd_df.loc[min_index])\n",
    "            mins_only.append(cd_df.loc[min_index])\n",
    "\n",
    "    mins_only_df = pd.DataFrame(mins_only)\n",
    "    # print(mins_only_df.N.values[:5].astype(np.longdouble))\n",
    "    # print(mins_only_df['N'].values[:5].astype(np.longdouble))\n",
    "    # print(np.fromstring(mins_only_df.N.values[:5], dtype=np.longdouble))\n",
    "\n",
    "    mins_only_df = mins_only_df[mins_only_df['N'] < 50000000]\n",
    "    mins_only_df.dropna(subset=[loss_name], inplace=True)\n",
    "\n",
    "    print(mins_only_df)\n",
    "    # df.rename(columns={})\n",
    "    return mins_only_df\n",
    "\n",
    "data = read_data(csv_file, loss_name=loss_name, col_names=col_names)\n",
    "x1s, x2s, Ys, ys = get_scaling_fit(data['N'], data['D'], data[loss_name])\n",
    "\n",
    "for x1, x2, Y, y in zip(x1s, x2s, Ys, ys):\n",
    "    print(f\"{x1}, {x2}, {Y}, {y}\")\n",
    "# x1, x2, y = get_scaling_fit(pd.concat([data2[data2['Model Type'] == 'Baseline']['N(Non-Embedding Parameters)'],\n",
    "#                                            data_iso[data_iso['Model Type'] == 'Baseline']['N(Non-Embedding Parameters)']]),\n",
    "#                             pd.concat([data2[data2['Model Type'] == 'Baseline']['N(Tokens)'],\n",
    "#                                            data_iso[data_iso['Model Type'] == 'Baseline']['N(Tokens)']]),\n",
    "#                             pd.concat([data2[data2['Model Type'] == 'Baseline']['dev log ppl'],\n",
    "#                                            data_iso[data_iso['Model Type'] == 'Baseline']['dev log ppl']]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlexp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
